REITH LECTURES 1976: Mechanics of the Mind
Colin Blakemore
Lecture 6: Madness and Morality
TRANSMISSION: 15 December 1976 – Radio 4

Gustav Fechner was the founder of a new and objective approach to the measurement
of mental events. He hoped that the kind of strict experiments that had beaten the
forces of nature into the laws of physics could work for the mind of man as well. Yet,
despite the orderly, reductionist nature of his ideas, Fechner, in 1860, permitted
himself an extraordinary speculation about personal consciousness. The brain is
bilaterally symmetrical; it has two sides, which are virtually mirror images of each
other. Nowhere is this clearer than in the cerebral hemispheres: there is a deep cleft
between the two halves, which are linked by an enormous strap, containing millions
of nerve fibres—the corpus callosum.
If consciousness is a property of the brain (which Fechner certainly believed), what
would happen if the cerebral hemispheres were literally split apart completely? As the
psychologist, William McDougall, reported in 1911, Fechner asserted ‘that if a man’s
brain could be mechanically divided into two parts without arresting the life of the
parts, the nervous activities of each part would be accompanied by its own stream of
consciousness.’
But McDougall was convinced that no mere split in the brain could divide the mind.
This hypothetical, inconceivable experiment of Fechner and McDougall has actually
been performed; and its results are, quite simply, some of the most fascinating
produced during research on the brain. The rationale behind this unlikely story is that
an epileptic seizure originating at a focus of damage on one side of the brain can
spread to the other hemisphere through the nerve fibres of the corpus callosum. The
attack then takes on the terrible proportions of a grand mal convulsion, involving the
whole body.
Now, in California, in the 1950s, experiments with animals had demonstrated that
cutting the corpus callosum did not interfere in a gross way with movement or any
vital function. So a bold (some would say reckless) surgeon decided to split the
corpus callosum in a few patients who had intractable epilepsy, in the hope that it
would moderate their fits. It did—to an unexpected extent. Not only did the
convulsions no longer involve both sides of the body, but they were reduced in
frequency, too, though the reason for this therapeutic bonus is still unknown. But what
of the other consequences of this unlikely invasion of the mind: who was right,
Fechner or McDougall?
Roger Sperry and his collaborators, at the California Institute of Technology, who had
already done much of the preliminary work with animals, had the chance to examine
these people whose brains had been split. At first, the patients seemed remarkably
normal; indeed, that had always been the conclusion in previous studies of people

1

who had suffered damage to the corpus callosum. However, careful and often
ingenious psychological testing revealed a bizarre mental syndrome.
Sperry took advantage of the known fact that the connections to and from one
hemisphere are mainly concerned with the opposite side of the body. If a split-brain
patient is blindfolded, and some familiar object, like a comb or a coin, is put into one
hand, he can use that same hand to retrieve the object from a collection of similar
things by touch alone. But ask the other hand to do it and the result is pure guesswork.
Imagine that the patient is looking fixedly at a point, and a picture of an object is
flashed momentarily just to the left of that point (so that it is seen only by the right
hemisphere, because of the distribution of nerve fibres from the eyes to the brain).
Now, the patient can select the object portrayed by sight, or even by touch alone,
when he uses his left hand, but not his right, to choose from an array of objects.
Each hemisphere, then, seems whole in itself, but with only half a body to serve it. In
Sperry’s words: ‘Everything we have seen so far indicates that the surgery has left
these people with two separate minds; that is, two separate spheres of consciousness.
What is experienced in the right hemisphere seems to be entirely outside the realm of
awareness of the left.’ Judged by any simple criterion, like seeing, feeling,
remembering or moving, there is not much to choose between the skills of the two
hemispheres. To that extent, Fechner was correct. Indeed, Sperry’s descriptions
convey an eerie impression that the split-brain patient is no longer one person, but
two: both hands do, indeed, have minds of their own.
But ‘mind-left’ and ‘mind-right’ are not equal in every respect. The biggest difference
between them (or, at least, the most obvious) is that one hemisphere—the left in all of
Sperry’s patients—does the talking. Put an object in the right hand or flash a picture
on the right of the visual field, and the patient, or rather his left hemisphere, can tell
you what it is. But show it on the left side, so that only the right hemisphere knows
about it, and the articulate left is lost for words. So the mind that makes its presence
felt, because it can speak, is that of the so-called major hemisphere, usually the left.
To that extent, McDougall was correct. The speechlessness, of the right hemisphere
has been seized upon by some as evidence that the consciousness of man cannot be
truly divided. But such an argument seems to me quite specious—rather like saying
that a brain- damaged patient who simply cannot speak, but can understand perfectly
well, is not conscious and therefore is not human.
The minor, right hemisphere is not even totally illiterate: it can read. When the word
‘comb’ is flashed on the left of a screen, so that only the right hemisphere can see it,
the patient cannot say what was written, but can reach with his left hand and select the
correct object from a choice. If a picture of a steaming cup of coffee is shown to the
right hemisphere, the left hand can point out, amongst an array of cards, the one with
the word ‘hot’ written on it. So adjectives as well as nouns are understood by ‘mindright’. But all the time the left hemisphere, speaking through the mouth of the patient,
has no idea what is going on. By all accounts, the right hemisphere is not very good
with verbs, but it does have the vocabulary and the syntactical ability of a young
child.
And what is more, in certain respects the subordinate right excels over the ‘dominant’
left. It is much better at any job that involves recognising patterns and shapes and,

2

particularly, complicated solid objects. The right hemisphere can draw quite well with
its left hand, but the left hemisphere even has problems in copying simple diagrams of
houses and cubes—it is much more at home writing than drawing. Recognising faces,
surely an immensely important part of human social behaviour, is also, apparently, a
speciality of the so-called ‘minor’ hemisphere.
Fascinating though these observations on split-brain people are, I believe they have
been misinterpreted in their relevance to the functions of the normal human brain.
Protagonists of different factions have all nurtured the idea that you and I have
virtually independent sides to our brains and therefore to our intellects. The dominant
side, usually the left, talks, writes, does mathematics, and thinks in a logical, serial
way; the minor right side recognises shapes and faces, appreciates music, puts on its
owner’s clothes and works in a global, intuitive fashion. The verbal, ordered culture
of the Western world, dominated by scientific and technological progress, is, we are
told, managed by the left hemispheres of its populations; the mystical, artistic and
religious cultures of the East must be driven by their right hemispheres.
There is a vocal movement that calls (presumably with its left hemisphere) for the
liberation of its right. Some psychologists, but most vociferously Robert Ornstein,
want a revolution in Western education with more emphasis on non-verbal skills and
the special attributes of the minor hemisphere, which are supposed to rule the cultures
of the East. I can’t help feeling that some Oriental Robert Ornstein, contemplating the
material progress that those attributes of the left hemisphere have given to the
Western world, might make just the opposite recommendation.
In fact, Hugh Sykes Davies, the scholar of English, recently attacked the ‘rightist’
movement, and complained that verbal skills are degenerating, not dominating, in our
society. All this fiery rhetoric seems to me to be based on a curious assumption that
the two hemispheres of a normal man are as divided as those of Sperry’s patients.
Under exceptional circumstances, in unusual people, the separate characteristics of the
two halves of the brain might come into conflict. The author, J. M. Barrie, for
instance, was ambidextrous; he even wrote his plays with either hand, and his desk is
worn smooth on both sides to prove it. He was sure that his two hands had different
characters and that he was in’ habited by two different people. But in most of us there
is a constant traffic of information between the two hemispheres, a tying-together of
separate experiences, a sharing of special talents.
What we should be striving to achieve for ourselves and our brains is not the
pampering of one hemisphere to the neglect of the other (whether right or left) or their
independent development, but the marriage and harmony of the two. It so happens
that the special mental territories of the minor hemisphere—spatial perception,
pictorial recognition and intuitive thought—are not easily amenable to conventional
education, nor is it clear that they would benefit from years of formal instruction.
Systems of education, especially higher education (and this applies to every culture)
seem designed to develop and exploit the powers of the hemisphere that is dominant
for speech, for those powers depend most on factual knowledge and prolonged
training.
The ripening of cerebral dominance is one of the most important processes in the
maturation of the brain. Unitary control of delicate motor skills, like speech and the

3

fine movements of the dominant hand, requires the firm planting of the special
apparatus for their control in one side of the brain. To ignore the special role and the
particular educational needs of the dominant hemisphere, and to encourage the minor
side to take charge may produce deleterious consequences in behaviour. It could
cause problems as profound as the disorders of emotion and speech, especially
stuttering, that are attributed to another cultural interference with cerebral
dominance—the forced use of the right hand in naturally left-handed children. This
form of social brain control was common in Europe and the United States, and was
virtually mandatory in the Soviet Union until quite recently.
The debate about liberating the minor hemisphere is only a fashionable twist to an
ancient and inextinguishable aspiration of man—to control his brain; or, more often,
to control someone else’s. The brain is the organ of behaviour, and the dream of every
leader, whether a tyrannical despot or a benign prophet, is to regulate the behaviour of
his people. There is a growing fear that a considerable fraction of brain research is
aimed at making such control a reality.
It is true that animals will work ceaselessly to receive electrical stimulation through
electrodes implanted in so-called ‘pleasure centres’ in their brains. The most effective
areas lie in the hypothalamus (which is involved in the regulation of motivated
behaviour, like eating, drinking and sex) and in the nearby limbic system (which is
thought to control emotions like rage, fear and joy). It is also true that electrical
stimulation at certain sites, or local damage at others, can calm the fiercest beast or
turn a placid animal into a savage killer. The physiologist, J. F. Fulton, wrote that a
certain tiny injury to a monkey’s brain ‘yields an animal that is formidably
ferocious…I finally had to decree that no one should ever examine (such a) monkey
alone, for…they attack to kill, and they single out the examiner’s neck as their initial
objective.’
There is, naturally, widespread apprehension, nurtured by popular publications and
not always discouraged by over-enthusiastic experimenters, that such techniques will
soon be part and parcel of everyday life. Such fears are, in the main, quite unfounded:
fortunately, the sheer paraphernalia of experimental brain manipulation, the implanted
electrodes, the cables and electronics, the tedious surgical techniques, make that kind
of brain control beyond the reach of any modern-day Alexander or Genghis Khan
who wishes to motivate an army or subjugate the world at the push of a button. And in
any case, are our brains not already more totally disciplined, our opinions more firmly
moulded, and our minds more sharply directed by the political and social environment
than by any electrode that could be put in our heads? The stentorian voices of the
mass media are more universally powerful than the indiscriminate persuasions of any
mind-altering drug.
More illuminating than pointing an accusing finger at the motives of brain research is
to ask why society always has attempted to regulate and order the behaviour of its
members. The answer might lie in a very basic biological need to identify—in order
to identify with.
Group selection is a term used to describe the operation of evolutionary forces on
closely-knit and inter-breeding groups of animals, not just individuals; it was
recognised by Charles Darwin as an important factor in the emergence of social

4

behaviour. By forming collaborative groups, largely based on family ties, animals can
improve their chances of surviving as a group, and hence of propagating their
common genes. Biologists even seek to explain the most cherished of human ethical
principles— altruism, heroism and unselfishness—in terms of group selection of
shared genetic material. J. B. S. Haldane once remarked that he was willing to lay
down his life— for two brothers or eight cousins! Now, the preservation of common
genes amongst a social group by such acts of co-operation and self-sacrifice would be
greatly enhanced by an ability of the individual to recognise in others those
similarities in appearance and behaviour that betray shared genes.
One of the major factors in the evolution of human society is the specialisation of the
brain to recognise and classify. That power may have had its origin in the
discrimination of genetic similarities and dissimilarities in other men. An animal, like
man, that could actively direct its altruism and shape its behaviour ethics to protect its
own genetically similar colleagues would have had an enormous advantage in group
selection. The roots of social discrimination today, then, lie in the group
discrimination of yesterday. The intolerance of difference has produced such social
cancers as apartheid in South Africa, the caste structure of India and the endless
warfare of Europe.
Many of the most precious elements in human social behaviour, such as formalised
sexual bonding and family structure, rich communal ceremony, and the embracing of
ethical principles within religious codes, can be viewed as deliberate cultural
exaggerations of inherited components of behaviour that favour group selection. The
desire to regulate behaviour, even to bring deviants back to the norm, may be a further
cultural embellishment of the logic of group selection.
Nowhere is this more evident than in the field of mental disease, where the questions
of social intolerance of difference and the danger of active brain control become most
profound. The problem of illness of the mind is a challenge not only to medicine but
also to society. Each year, one man in 14, one woman in seven, consult a doctor about
some form of mental disease; every year, 600,000 people in Great Britain are referred
to psychiatrists. Because the very symptoms of mental disease are defined as
aberrations of behaviour, they bring the sufferer into conflict with the community in a
way that no illness of any other organ can. Diseases of the mind are an insult to the
behavioural order on which society rests. Most of all, they are usually disorders of
emotion, a function that the human mind has so carefully concealed under its
cognitive skin.
It is no coincidence that, in history, the same treatments have been meted out to the
mentally sick as to those other offenders against the order of society—the criminal
and the heretic. At best, they have had their demons cast out or merely been
imprisoned; at worst they have been tortured to death.
Textbooks of psychiatry try to achieve the same as the codes of secular law or
religious commandments; they all attempt to establish definitions and boundaries for
normal behaviour. But just as the law adjusts to the nature of crime, just as heretics
alter the religion that they offend, so cultural evolution has benefited from certain
extremes of behaviour. Visionaries like Joan of Arc and William Blake, artists like
Van Gogh and Edvard Munch, were, by conventional definition, mentally disturbed.

5

The paradox of cultural evolution is that, as it gains from the contribution of those
people who deviate significantly from the norm in intelligence or inventiveness, in
artistry or in insight, it also builds up resistance to change, and distrust of extremes,
by its emphasis on group identity.
The more revolutionary schools of psychiatry—for example, that of R. D. Laing —
argue that the definition of sickness of the mind is a product of a fault in society itself.
The anthropological extension of this viewpoint maintains that, since mental illness is
culturally relative, those whom we call mad might be able to function usefully in
societies that we call primitive. The delusions and hallucinations of the schizophrenic
might be admired, and the mentally ill could fill important roles such as shaman, or
witch-doctor. But recent, careful studies of Alaskan Eskimos and the Yoruba of rural
Nigeria have cast doubt on the opinion that the ‘illness’ of mental disturbance is
merely and entirely a label that is tied on socially unacceptable behaviour. Both of
these peoples have special names for mental illness, nuthkavihak for the Eskimo, were
for the Yoruba, and neither ethnic group applies those terms to their shamans and
healers. The shaman in a trance is described by an Eskimo as ‘out of his mind’, but
not ‘crazy’. There is little respect for those who are thought to be genuinely mad: they
are shackled or sedated by the Yoruba healer, they are tied to posts or locked in barred
igloos by the Eskimos.
But if mental illness is not a unique product of our way of life, its definition has been
stretched to make use of the special powers that society has assumed for dealing with
those that it defines as different. In their book, A Question of Madness, Zhores and
Roy Medvedev give a moving and bitter account of the enforced incarceration of
Zhores Medvedev, the eminent Russian scientist, in a mental hospital, because of his
stubborn opposition to local party bureaucrats and his public pronouncements against
the Soviet state. Under the frighteningly broad definition of ‘creeping schizophrenia’
that is employed by orthodox Russian psychiatry, Medvedev was declared to be
suffering from paranoia because he showed ‘poor adaptation to the social
environment’. Medvedev himself was relatively fortunate; he spent only 19 days in
that ‘political asylum’ before the torrent of protest organised by his brother led to his
release. But others are not so lucky; and the abuse of psychiatric definition continues.
Although we are right to be indignant about this flagrant affront to personal liberty in
the USSR, we should not believe that our own approach to mental disease is without
fault. A lack of sound theoretical knowledge makes even adequate diagnosis unlikely.
In a recent survey, 200 children who had been diagnosed as autistic were subjected to
a second opinion. Only 33 were diagnosed as autistic by the second examiner, 53
were said to be childhood schizophrenics, 51 retarded, seven deaf, and so on.
Just as the criteria for diagnosis are not rigid, so the methods of treatment are largely
empirical. The use of surgical damage to the brain in the treatment of the mentally ill
is certainly the closest that we come to the horror of socially-applied control of the
brain, and it illustrates both the inadequate restraints on the treatment of the mentally
sick and the poor theoretical basis for that therapy.
In some cases, like the use of the split- brain technique for the treatment of epilepsy,
the methods and consequences had been carefully worked out beforehand with
experimental animals. But psychosurgery, the treatment of emotional disorders by

6

operations on apparently healthy brain tissue, proceeds with a lack of experimental
background that would be considered inadequate in all other areas of medicine.
The whole of psychosurgery had its origins in a research report delivered by C.
Jacobsen and J. F. Fulton at a conference of neurologists in London in 1935. They had
been training two chimpanzees to remember where a morsel of food was hidden. One
of them, called Becky, was particularly temperamental and became extremely
distressed when she failed at this task. She would fly into a tantrum and ref use to
perform when the food was hidden from view. Fulton and Jacobsen performed
surgical removal of part of the frontal lobes of the cerebral hemispheres and they
reported that Becky no longer became disturbed during the experimental task.
A Portuguese neuropsychiatrist, Egas Moniz, rose after the talk and asked: ‘If frontal
lobe removal prevents the development of experimental neuroses in animals and
eliminates frustration behaviour, why would it not be feasible to relieve anxiety states
in man by surgical means?’ Within the year, Moniz and the surgeon, Almeida Lima,
had started to perform operations on the frontal lobes of deranged patients, and by
1950 some 20,000 people around the world, including prisoners and children, had
been treated this way. And all of this stemmed from an almost anecdotal observation
on a single, nervous chimpanzee.
Worst of all, the effectiveness of these operations was evaluated by the very surgeons
who had invested their careers in psychosurgery: failure was not easy to accept. And
with any treatment for the mentally ill, it is difficult to establish with certainty the
success of the technique itself because of the fairly high rate of spontaneous remission
from symptoms and the undoubted value of the extra attention that special patients
receive, whatever their treatment. However, it became clear that the benefits of gross
psychosurgical methods were often minimal and sometimes the consequences were
disastrous. Moniz himself, who won the Nobel Prize in 1949, was shot in the spine by
one of his own lobotomised patients.
But once established psychosurgery became self-sustaining. It is still widely practised.
The techniques are more sophisticated and the surgical lesions much more discrete,
but the lack of moral restraint and theoretical background is just as serious.
Significantly, some of the strongest criticism of psychosurgery comes from the
behavioural scientists whose experiments are quoted as justification for the surgical
methods. Destruction of the amygdala, a part of the limbic system, is used as a
treatment for extreme aggression, although in animals damage to the amygdala
sometimes increases aggressive behaviour. Aggressive patients have also been
subjected to lesions of part of the hypothalamus, dangerously close to regions
involved in the regulation of eating and drinking. The rationale behind this procedure
is that a similar operation in cats can abolish the ferocious behaviour that results from
an earlier injury to another limbic structure, the septum. But the septum is not even a
clearly defined area in the human brain! Other parts of the hypothalamus are
destroyed as treatments for obesity and even a symptom called ‘latent homosexuality’.
That other widely used technique, electroconvulsive therapy, which undoubtedly has
brought relief to many of the mentally ill, is, nevertheless, based on even more obtuse
and spurious theoretical justification.

7

The present-day use of convulsive therapy stems from a revival of the 18th- century
opinion that maniacs were best treated by a very severe physical stress, and from the
entirely erroneous view that epileptics are protected from schizophrenia by their
natural convulsions.
Of course, medicine must work empirically until it has sound theoretical grounds for
action. Sick people need to be treated.
But in most fields of medicine, empirical art has been rationalised, modified or
supplemented through experimentally-derived knowledge of how the body works.
New methods of treatment have grown out of careful and thorough experimental
work. In the management of many diseases of the brain, this is not yet the case. To
that extent, some aspects of neurology and psychiatry are like mediaeval alchemy
practised with 20th-century tools.
It is true that the growing use of drugs in psychotherapy, which is also not without its
critics, has dramatically reduced the number of long-term admissions to mental
institutions. But, far more important, the intensive research on the action of
therapeutic drugs, much of it demanded by law before they can be used, begins to
offer hope of an explanation of the biochemical basis at least of schizophrenia.
There is, then, the promise that research on the brain will provide a genuine rationale
for the treatment of mental disease. But much more than that, it will give a greater
understanding of the nature of man himself. The study of the brain is one of the last
frontiers of human knowledge and of much more immediate importance than
understanding the infinity of space or the mystery of the atom. For without a
description of the brain, without an account of the forces that mould human
behaviour, there can never be a truly objective new ethic based on the needs and
rights of man. We need that new ethic if we are to overcome the intolerance of
difference, which has entrenched society in dogma and discrimination—to dispel the
naturalistic fallacy of arguing that the way we do behave is the way we must and
ought to behave.
I began with talk of revolution and I end on the same note. Revolution, social as well
as scientific, grows out of knowledge. Only when the choices for action are
transparent can proper choice be made. In the words of Mao Tse-Tung: ‘We can learn
what we did not know. We are not only good at destroying the old world; we are also
good at building the new.’
I have described the brain as an organ, as a part of the body no more magical than the
heart and the liver, which were themselves once thought to do the job of the brain. But
also I have tried to show that the actions of the brain are quite unlike those of any
other organ, because they determine the behaviour of one man towards his fellows.
The brain struggling to understand the brain is society trying to explain itself.

8

